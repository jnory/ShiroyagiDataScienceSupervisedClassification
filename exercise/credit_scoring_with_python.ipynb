{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習 : クレジットカードの支払履歴とデフォルトのデータを使ったモデリング\n",
    "\n",
    "datasetフォルダにある\"UCI_Credit_Card.csv\"は2005年4月~9月の顧客別のクレジットカードの支払履歴及び翌月にデフォルトしたかどうかのデータセットです。\n",
    "本データは、https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset から取得しました。\n",
    "\n",
    "### 課題\n",
    "あなたはカード会社のデータサイエンティストです。\n",
    "現在デフォルト率が約22%となっており、デフォルト率を下げるとともに、機会損失も返済不能に陥る実際の損失も最小化するモデルを作るように依頼されました。\n",
    "「今回は中身はBlackboxで良いから、とにかく当ててくれ！」という依頼がきています。\n",
    "あなたはどのようなモデルを作りますか？\n",
    "\n",
    "### 注意\n",
    "* データセットは以下の2つに分割しています\n",
    "    * train_UCI_Credit_Card.csv\n",
    "    * test_UCI_Credit_Card.csv\n",
    "* モデリングはtrain_UCI_Credit_Card.csvをのみを使ってください。\n",
    "* test_UCI_Credit_Card.csvを答え合わせに使います。\n",
    "* 私が作成したevaluate_test_data関数に以下を指定してください\n",
    "    * 学習済みのモデル\n",
    "    * 推定デフォルト確率をいくつ以上であればローンを出さないこととするかを決めるcut_off\n",
    "    * テストデータ\n",
    "\n",
    "### ヒント\n",
    "* 特徴量を頑張って作る\n",
    "* アルゴリズムやモデル選択の際に、\n",
    "\n",
    ">### Dataset Information\n",
    "\n",
    ">This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    ">### Content\n",
    "\n",
    ">There are 25 variables:\n",
    "\n",
    ">ID: ID of each client\n",
    "\n",
    ">LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "\n",
    ">SEX: Gender (1=male, 2=female)\n",
    "\n",
    ">EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "\n",
    ">MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "\n",
    ">AGE: Age in years\n",
    "\n",
    ">PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "\n",
    ">PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "\n",
    ">PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "\n",
    ">PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "\n",
    ">PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "\n",
    ">PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "\n",
    ">BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "\n",
    ">BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "\n",
    ">BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "\n",
    ">BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "\n",
    ">BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "\n",
    ">BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "\n",
    ">PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "\n",
    ">PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "\n",
    ">PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "\n",
    ">PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "\n",
    ">PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "\n",
    ">PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "\n",
    ">default.payment.next.month: Default payment (1=yes, 0=no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "try:\n",
    "    xrange\n",
    "except NameError:\n",
    "    xrange = range\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み\n",
    "\n",
    "まず、データを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 列名の確認\n",
    "\n",
    "どんな列があったかを思い出しましょう。PandasのDataFrameは、DataFrame.columnsとやると、列名を確認できます。\n",
    "\n",
    "ここでは、見やすいように、forループを回しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for colname in train_data.columns:\n",
    "    print(colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量の設計（Feature Engneering)\n",
    "みなさんの想像を膨らませて、新たな変数を作ってください。\n",
    "\n",
    "例: BILL_AMTを全部足しあげて、新しい列：BILL_AMT_TOTAL　を作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data[\"BILL_AMT_TOTAL\"] = train_data[\"BILL_AMT1\"] + train_data[\"BILL_AMT2\"] + train_data[\"BILL_AMT3\"]  + train_data[\"BILL_AMT4\"] + train_data[\"BILL_AMT5\"] + train_data[\"BILL_AMT6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## developmentデータを作っておきましょう。\n",
    "\n",
    "ここでは、学習に使うデータとチューニング用のデータとを 80:20に分けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data2, dev_data = train_test_split(train_data, test_size = 0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of Rows: \", train_data2.shape[0])\n",
    "train_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of Rows: \", dev_data.shape[0])\n",
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習のアルゴリズムをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#講義ではカバーしていませんが、興味がある方はこちらもどうぞ \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "# from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例: ロジスティック回帰の場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まず、説明変数と被説明変数を決めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor_feature = [\"BILL_AMT_TOTAL\", \"AGE\"] #説明変数\n",
    "target_feature = \"default\" #被説明変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### もし特定の列だけ抜きたいのあれば、こんなやり方もあり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude_cols = [\"ID\", \"default\"] #除外したい列をこちらに入れておきます。\n",
    "predictor_feature = []\n",
    "\n",
    "for colname in train_data.columns:\n",
    "    #除外したい列に列名が含まれていなければ、True\n",
    "    if colname not in exclude_cols:\n",
    "        predictor_feature.append(colname)  #predictor_featureのリストに追加\n",
    "\n",
    "print(predictor_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#学習データ\n",
    "train_X = train_data2[predictor_feature]\n",
    "train_y = train_data2[target_feature]\n",
    "\n",
    "#Developmentデータ\n",
    "dev_X = dev_data[predictor_feature]\n",
    "dev_y = dev_data[target_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まず初期化します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 続いて、とりあえず学習させます（チューニングなし）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developmentデータで試します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_y_pred_proba  = clf.predict_proba(dev_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2値分類問題ですので、このように2列で出力されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  チューニングをしてみます\n",
    "\n",
    "例： Logistic regressionのパラメーターはCです（これはオーバーフィッティングを防ぐための罰則、ペナルティの強さを表します）\n",
    "ここではF1-measureを目安にチューニングしてみましょう。また、カットオフ値は決め打ちで0.24にしておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#パラメータの候補を出しておきます。\n",
    "C_cancidates = np.array([0.01, 0.1, 1.0, 10, 100])\n",
    "\n",
    "#決め打ちのCut offを指定します。\n",
    "cut_off = 0.24\n",
    "\n",
    "#トラックしたい評価指標を入れておく、空っぽのリストを用意します。\n",
    "f1_measure_history = []\n",
    "\n",
    "#Forループでパラメータの候補を一つずつ試します。\n",
    "for each_C in C_cancidates:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Parameter C = \", each_C)\n",
    "    \n",
    "    #初期化\n",
    "    clf= LogisticRegression(C=each_C)\n",
    "    \n",
    "    #学習\n",
    "    clf.fit(train_X, train_y)\n",
    "    \n",
    "    #devデータで予測します（2列のデータで出てくるので、2列目、つまりデフォルトする確率だけを抜き取ります）\n",
    "    dev_y_pred_proba = clf.predict_proba(dev_X)[:,1]\n",
    "    \n",
    "    #貸さないなら、1、貸すなら0にします。\n",
    "    pred_flag = (dev_y_pred_proba >cut_off ).astype(int)\n",
    "    \n",
    "    #混同行列を出力します。\n",
    "    print(confusion_matrix(y_pred=pred_flag, y_true=dev_y))\n",
    "    \n",
    "    #F1scoreを計算します\n",
    "    each_f1_score = f1_score(y_pred=pred_flag, y_true=dev_y)  #もしF1scoreではなく、precisionやrecallを使いたい場合は変えましょう\n",
    "    print(\"F1 score: \", each_f1_score)\n",
    "    \n",
    "    #最後に、f1_measure_historyにそれぞれのf1 scoreを追加します。\n",
    "    f1_measure_history.append(each_f1_score)\n",
    "\n",
    "#Forループが終わったら、一番よかったf1 scoreを取り出し、対応するパラメータを出力します。\n",
    "max_score = max(f1_measure_history)\n",
    "best_param = C_cancidates[np.array(f1_measure_history) == max_score]\n",
    "print(\"Max score: \", max_score, \"When C =\", best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チューニング後のモデルを学習しておきましょう（後で、テストデータに適用するために）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mybest_model = LogisticRegression(C=1.0)\n",
    "mybest_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失額を計算するための関数: evaluate_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_test_data(mymodel, cut_off, data_df, predictor_feature, target_feature, verbose = True):\n",
    "    \n",
    "    # TO DO: \n",
    "    #もしtrainデータで新しい列を作成したらtest_dataでも作ってください\n",
    "    #trainingデータで作成した変数を作っておきます。\n",
    "    data_df[\"BILL_AMT_TOTAL\"] = data_df[\"BILL_AMT1\"] + data_df[\"BILL_AMT2\"] + data_df[\"BILL_AMT3\"]  + data_df[\"BILL_AMT4\"] + data_df[\"BILL_AMT5\"] + data_df[\"BILL_AMT6\"]\n",
    "    \n",
    "    \n",
    "    X = data_df[predictor_feature]\n",
    "    y = data_df[target_feature]\n",
    "    \n",
    "    #デフォルト確率の予測\n",
    "    y_pred_proba = mymodel.predict_proba(X)[:,1]\n",
    "    \n",
    "    #cut_offより大きければデフォルトする=つまりローンを出さない\n",
    "    pred_flag = (y_pred_proba >cut_off ).astype(int)\n",
    "    \n",
    "    #予測精度の確認(Confusuion Matrix)\n",
    "    if verbose:\n",
    "        print(confusion_matrix(y_true=y, y_pred=pred_flag))\n",
    "        print(\"Accuracy: \", accuracy_score(y_true=y, y_pred=pred_flag))\n",
    "        print(\"Recall: \", recall_score(y_true=y, y_pred=pred_flag))\n",
    "        print(\"Precision: \", precision_score(y_true=y, y_pred=pred_flag))\n",
    "        print(\"F1 score: \", f1_score(y_true=y, y_pred=pred_flag) )\n",
    "    \n",
    "    #テストデータのデフォルト率\n",
    "    base_default_rate = np.mean(y)\n",
    "    if verbose:\n",
    "        print(\"テストデータのデフォルト率: \", base_default_rate)\n",
    "    \n",
    "    #デフォルトしないと予測した中で本当にデフォルトした人の割合\n",
    "    fail_rate = np.mean(y[pred_flag==0])\n",
    "    if verbose:\n",
    "        print(\"デフォルトしないと予測した中で本当にデフォルトした人の割合: \", fail_rate)\n",
    "    \n",
    "    #本当は貸した方がよかったのに、貸さなかったバランス（機会ロス）\n",
    "    oploss_idx = np.logical_and(y==0, pred_flag==1)\n",
    "    opportunity_loss = sum(data_df[\"LIMIT_BAL\"][oploss_idx])\n",
    "    if verbose:\n",
    "        print(\"本当は貸した方がよかったのに、貸さなかったバランス（機会ロス）: \" , opportunity_loss)\n",
    "    \n",
    "    #本当は貸さない方がよかったのに、貸してしまったバランス（返済不能額）\n",
    "    realloss_idx = np.logical_and(y==1, pred_flag==0)\n",
    "    realized_loss = sum(data_df[\"LIMIT_BAL\"][realloss_idx])\n",
    "    if verbose:\n",
    "        print(\"本当は貸さない方がよかったのに、貸してしまったバランス（返済不能額）: \" , realized_loss)\n",
    "    \n",
    "    #Total loss\n",
    "    \n",
    "    total_loss = opportunity_loss + realized_loss\n",
    "    if verbose:\n",
    "        print(\"Total Loss: \", total_loss)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## devデータを使って、cut_off値を最適化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カットオフ値の候補を作る(numpyのarangeで作れます）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut_off_candidates = np.arange(0, 1, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一つずつ試しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_loss_history = []\n",
    "for each_cut_off in cut_off_candidates:\n",
    "    each_total_loss = evaluate_test_data(mymodel=mybest_model, \n",
    "                                         cut_off=each_cut_off, \n",
    "                                         data_df=dev_data, \n",
    "                                         predictor_feature=predictor_feature, \n",
    "                                        target_feature = target_feature, \n",
    "                                        verbose = False)\n",
    "    \n",
    "    total_loss_history.append(each_total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最小のTotal Lossを探す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #リストだとやりにくいので、Numpyの配列にしておきます\n",
    "cut_off_candidates_ar = np.array(cut_off_candidates)\n",
    "total_loss_history_ar = np.array(total_loss_history)\n",
    "\n",
    "#グラフにします\n",
    "plt.plot(cut_off_candidates,  total_loss_history)\n",
    "best_cut_off  = cut_off_candidates_ar[total_loss_history_ar == min(total_loss_history_ar)]\n",
    "print(\"Total Loss: \", min(total_loss_history), \"When cut off = \", best_cut_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータで試してみよう（これは演習の最後の1回だけ！）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test_UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いよいよ、テストデータで検証してみます（evaluate_test_dataで、特長量の設計をしていたら、関数内に書いておかないだめですよ）\n",
    "\n",
    "ドキドキしますね！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_test_data(mymodel=mybest_model, \n",
    "                   cut_off = 0.2, \n",
    "                   data_df = test_data, \n",
    "                   predictor_feature = predictor_feature, \n",
    "                   target_feature = target_feature,\n",
    "                   verbose = True\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
